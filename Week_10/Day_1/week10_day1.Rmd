---
title: "R Notebook"
output: html_notebook
editor_options: 
  markdown: 
    wrap: sentence
---

# 1 MVP

The file project_management.csv contains data sampled from the recent work schedule of a small construction company.
Column estimated_length contains the estimated length of a building job in days, while column actual_length contains the actual recorded length of the job in days.

We are interested in determining the accuracy of the job estimations made by the company using simple linear regression, so we will eventually want to run a simple linear regression using actual_length as the dependent variable, and estimated_length as the independent variable.

## Load the data into a dataframe project

```{r}
library(tidyverse)
library(janitor)
library(modelr)
library(broom)
library(ggfortify)
library(ggplot2)
```

```{r}
pro_man <- read_csv("data/project_management.csv")
```

## Plot the data

taking estimated_length as the independent variable and actual_length as the dependent variable.

```{r}
pro_man %>% 
  ggplot(aes(estimated_length, actual_length)) +
  geom_point() +
  labs(
        x = "\nEstimated length (days)",
        y = "Actual length (days)\n",
        title = "Length of building projects",
        subtitle = "for a small construction firm\n"
        ) 
```

## Calculate the correlation coefficient

of estimated_length and actual_length and interpret the value you obtain.

```{r}
pro_man %>% 
  summarise(cor(estimated_length, actual_length))

```

A correlation coefficient of 0.80 suggests a very strong positive correlation.
Of course, as we all know, correlation is not causation.

## Perform a simple linear regression

using actual_length as the dependent variable, and estimated_length as the independent variable.
Save the model object to a variable.

```{r}
model <- lm(formula = actual_length ~ estimated_length, data = pro_man)
model
```

## Interpret the regression coefficient of estimated_length

(i.e. slope, gradient) you obtain from the model.
How do you interpret the r2 value reported by the model?

The best fit found by R is:

actual length = 1.1416 + 1.223 * estimated length

We can see what the fitted values for the outcome variable (the actual length) that the model returns:

```{r}
fitted(model)
```

## Is the relationship statistically significant?

Remember, to assess this you need to check the p-value of the regression coefficient (or slope/gradient).
But you should first check the regression diagnostic plots to see if the p-value will be reliable (don't worry about any outlier points you see in the diagnostic plots, we'll return to them in the extension).

```{r}
glance_output <- clean_names(glance(model))
glance_output
```

```{r}
tidy(model)
```

Using summary statistics we can get an idea of the p-value shown in the model but we can go into more detail.

```{r}
glance_output$r_squared

```

## Using diagnostic plots

```{r}
autoplot(model)
```

### Residuals vs Fitted

This plot tests the independence of residuals - ideally it would be scattered around the zero, which is largely the case for the values in this sample.

### Normal Q-Q

This quantile-quantile plot tests the normality of the residuals.
Ideally you would like all of the points to lie close to the line and this is largely the case - so the residuals are well-described as normally distributed.

### Scale_Location

This plot tests the constancy of variation of the residuals.
Ideally, you want the residuals to occur in a band of fixed width above the x-axis.
The values are loosely plotted around the line.

```{r}
pro_man <- pro_man %>%
  add_predictions(model) 

pro_man %>%
  ggplot(aes(x = estimated_length)) +
  geom_point(aes(y = actual_length)) +
  geom_line(aes(y = pred), col = "red") +
  labs(
        x = "\nEstimated length (days)",
        y = "Actual length (days)\n",
        title = "Predicting length of projects"
        ) 
```

A graph showing the predicted values shows that there is a correlation between the estimated length of projects and the actual length of projects. (With one obvious outlier.) 




# 2 Extension - Residuals vs Leverage

Read this material on the leverage of points in regression, and how to interpret the Residuals vs Leverage diagnostic plot produced by plotting the lm() model object.
So far we've been using the autoplot() function to plot the model objects produced by lm(), but you can see the base R equivalent by doing something like plot(model) where model is an lm() object.

Return to your plot from earlier, and now label the data points with their row number in the data frame using geom_text() [Hint - you can pass aes(label = 1:nrow(project)) to this layer to generate row index labels] 


```{r}
pro_man %>% 
  ggplot(aes(estimated_length, actual_length)) +
  geom_point() +
  geom_text(label = 1:nrow(pro_man),
                    nudge_x = 0.25, nudge_y = 0.25, 
                    label.size = 0.15,
                    check_overlap = T) +
  labs(
        x = "\nEstimated length (days)",
        y = "Actual length (days)\n",
        title = "Length of building projects",
        subtitle = "for a small construction firm\n"
        ) 
```
Identify by eye any points you think might be outliers and note their labels.
Further split your outliers into those you think are 'influential' or 'non-influential' based on a visual assessment of their leverage.
The main outlier is row 5 and possibly row 18.



Use your model object from earlier and confirm your visual assessment of which points are 'influential' or 'non-influential' outliers based on Cook's distance.
You can get a useful plot of Cook's distance by passing argument which = 4 to autoplot().
Or try the base R plot() function for comparison [e.g.
plot(model); you can also use par(mfrow = c(2,2)) just before the plot() command to get a nice two-by-two display]!

```{r}
par(mfrow = c(2,2))
plot(lm(actual_length ~ estimated_length
        ,data=pro_man)) 
```

```{r}
plot(lm(actual_length ~ estimated_length
        ,data=pro_man)) 
```

Obtain the intercept and regression coefficient of variable estimated_length for a simple linear model fitted to data omitting one of your non-influential outlier points.
How different are the intercept and coefficient from those obtained above by fitting the full data set?
Does this support classifying the omitted point as non-influential?
Plot the data points, this regression line and the regression line for the full data set.
How different are the lines?

Repeat the procedure above, but this time omitting one of your influential outliers.
3 Additional resources There are various techniques to perform what is known as 'robust regression' on a dataset.
Robust methods are less affected by the presence of outliers.
See the rlm() function ('robust linear model') in the MASS package and this blog post.
